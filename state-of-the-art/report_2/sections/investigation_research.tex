\section{Investigation/Research}

In this section we describe our investigation and research over the proposal readings. Investigation throughout the examination of the reading facts, novel possibilities and results. Also, addressing the research reasoned conclusions of those readings.

\subsection{Classifier Predictors}

Many learning-based algorithms are able to solve problems that previously seemed completely impossible. They can look at an image and describe what they depict in a sentence, or even turn medical diagnosis into a much more accurate by giving doctor's a second opinion. Amazing new results keep appearing every single week. However, an important thing that we need to solve is that if we deploy these Neural Networks (NN) in a production environment, we would want to know if we are relying on a good or bad decision. The narrative is very simple: if we do not trust a classifier, we will not use it. And perhaps the best way of earning the trust of a human would be if the Artificial Intelligence (AI) could explain how it came to a given decision.

Strictly speaking, a NN can explain it to us, while showing us hundreds of thousands of neuron activations that are completely unusable for any sort of intuitive reasoning. That said, what is even more difficult to solve is that this explanation happens in a way that we can interpret. An earlier approach has use decision trees that described what the learner looks at and how it uses this information to arrive to a conclusion. The work presented with the title \textit{“Why Should I Trust You?” Explaining the Predictions of Any Classifier} from Ribeiro et al. \cite{ribeiro2016should} new work is quite different. For instance, imagine that a NN would look at all the information we know about a patient and tell us that this patient likely has the flu. Also, in the meantime, it could tell us the fact that the patient has a headache and sneezes a lot contributed to the conclusion that he has the flu, but, the lack of fatigue is notable evidence against it. Our doctor could take this information and instead of blindly relying on the output, could make a more informed decision.

Other related works \cite{giger2013breast, carneiro2017automated} are describing an automated methodology for the analysis of unregistered medical imaging views in order to estimate the patient's risk of developing cancer. The main innovation behind this methodology lies in the use of Deep Learning (DP) models for the problem of jointly classifying unregistered medical imaging views and respective segmentation maps of lesions. This is a holistic methodology that can classify medical imaging exams, containing several modality of views and the segmentation maps, as opposed to the classification of individual lesions, which is the dominant approach in the field. The authors also demonstrate that the proposed system is capable of using the segmentation maps generated by automated detection systems, and still producing accurate results.

\clearpage

A big additional selling point is that these techniques are model agnostic, which means that it can be applied to other learning algorithms that are able to perform medical classification. For example, complementing medical imaging with medical text (e.g. patient's clinical history). It is also a possibility that an AI is only right by chance, and if this is the case, we should definitely know about that. And here, in this example, with the additional explanation, it is rather easy to find out that we have a bad model that looks at some modality of the medical image and acknowledge if it is a severe lesion or not.

The tests indicate that humans make significantly better decisions when they lean on explanations that are extracted by these techniques. Therefore, the work done by these authors is important to our work and might be analysed by us. It is also an introduction to the Human-In-The-Loop topic. Consequently the topic must be analysed, also. The source code of this project is also \href{https://github.com/marcotcr/lime}{available} and should be our interest to follow it as an example of a potential tool.

\subsection{Precise Selection Techniques}

A work done by Benko et al. \cite{benko2006precise}, called \textit{Precise Selection Techniques for Multi-Touch Screens}, addresses a set of techniques, which leverage the development of multitouch sensitive displays, helping users to select very small targets. This work seems interesting to our work, since the techniques hereby presented can be applied to our system, facilitating the interaction of the radiologists with it. Our idea based on this work, is to bring the presented techniques to support our radiologist's annotations over both: (i) the thresholds of the masses; and (ii) the micro-calcifications.

In this work, the authors are presenting five techniques that can be used by us. The techniques are listed by us as follows.

\hfill

List of the five techniques proposed to our work:

\hfill

\begin{enumerate}
\item Offset;
\item Midpoint;
\item Stretch;
\item X-Menu;
\item Slider;
\end{enumerate}

\hfill

These techniques are facilitating pixel-accurate targeting while adjusting display ratio of the control with a secondary interactive input. The authors could also contribute to our work by a "clicking" technique , the Simulated Pressure (SimPress), which reduces motion errors during clicking and allows us to simulate a hover state on medical devices unable to sense proximity. They implemented their techniques on a prototype that offers computer vision-based tracking. The vision-based tracker can also be useful to us. In their formal user study, the authors tested the performance of most promising techniques against a baseline (Offset), on target sizes and input noise levels. All chosen techniques outperformed the control technique in terms of error rate reduction and were preferred by participants.

Their study results show that their \textit{Selections} techniques are presenting viable solutions for increasing precision and accuracy in a small target selection task. Overall, these techniques provide a palette of interactions and applications for our medical imaging field from which the radiologist may chose depending on the application.